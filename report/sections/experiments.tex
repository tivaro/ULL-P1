\section{Experiments}

\subsection{Evaluation metrics}

Following \cite{Goldwater200921}, we define two types of evaluation metrics: the joint probability of the corpus and retrieval measures.

\subsubsection{Corpus probability}

For the DP model, the joint probability over all the words in the corpus is defined for as follows:

\begin{equation}
p(\mathbf{w} | \alpha, P_0) = \prod_{w_i \in \mathbf{V}} \left( \frac{n_{w_i} - 1 + \alpha P_0(w_i)}{N - 1 + \alpha} \right)^{n_{w_i}}
\end{equation}

where $\mathbf{V}$ is the lexicon or vocabulary, $N$ is the total number of words in the corpus, and $n_{w_i}$ is the number of occurences of word $w_i$ in the corpus.

\subsubsection{Retrieval measures}

We assess the quality of the retrieved segmentation using precision, recall and the $F_0$ measure. Like \cite{Goldwater200921}, we evaluate these measures on words (per utterance), on boundaries (per utterance, excluding the start and end of the utterance), and on the lexicon. This gives us nine retrieval measures for each experiment.

\subsection{$P_0$ distribution}

$P_0$ is the prior distribution over phonemes. We experiment with a uniform distribution, and one that is based on proportional counts in the corpus. We evaluate using the log joint probability over time.

\subsection{Gibbs sampling}

The retrieved segmentation depends in part on the Gibbs sampling procedure. We experiment with different temperature regimes and initialisation strategies. Like the choice of $P_0$ distribution, we evaluate the temperature regimes and initialisation strategries using the log joint probabiliy over time.

\subsubsection{Temperature regime}

We experimented with three different temperature regimes:

\begin{itemize}
\item Regime 0: 20000 iterations, from 0.1 to 1 in evenly spaced steps of 0.1
\item Regime 1: 30000 iterations, from 0.1 to 1.5 in evenly spaced steps of 0.1
\item Regime 2: 40000 iterations, from 0.002 to 1 in evenly spaced steps of 0.002
\end{itemize}

\subsubsection{Initialisation}

In all experiments, the boundaries are initialised randomly. We experimented with the proportion of boundaries that were initialised with respect to the total number of possible boundaries (per utterance). We tested proportions $0$, $\frac{1}{3}$, $\frac{2}{3}$, $1$.

\subsection{Model parameters}

The parameters of the DP model are $\alpha_0$, which affects the number of word types proposed, and $p_\#$, the prior probability of a word boundary. We experiment with $\alpha_0 \in \{1, 2, 5, 10, 20, 50, 100, 200, 500\}$ and $p_\# \in \{0.1, 0.3, 0.5, 0.7, 0.9\}$. During the $\alpha_0$ experiments we kept $p_\#$ fixed to 0.5 and during the $p_\#$ experiments we kept $\alpha_0$ fixed to 20.

\subsection{PYP Model}

Because $h^{-}$ has to be modelled explicitly in the PYP model, the sampling is computationally a lot more expensive than the sampler used in DP sampling. Therefore a different iteration scheme was used with only 4000 iterations, and three equal temperature steps (0.1, 1.1, 1.6).

\subsection{Algorithm}
Because the Gibbs sampling in the PYP model is slightly more complicated than the sampler for the DP model, some experiments were run, to test wether the sampler was implemented correctly.
First, the PYP model was run with the $\beta$ parameter set to 0. The results were compared to the DP model with the exact same parameters and temperature regime. Both models were expected to produce the same results.

Next, the probability of the corpus was calculated and examined after each iteration. If the sampler was implemented

\subsection{Parameters}
Both the concentration paramter $\alpha$ and the smoothing paramter $\beta$ effect the seating distribution and might therefore interact with eachother. In order to find the best settings for $\alpha$ and $\beta$, a grid search was conducted with $\alpha \in \{1, 2, 5, 10, 20, 50, 100, 500 \}$ and $\beta \in \{ 0.01, 0.1, 0.2, 0.4,0.6, 0.8, 1, 0 \}$
