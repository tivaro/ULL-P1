\section{Introduction}

The problem of how infants learn to identify individual words in spoken language has been the topic of many research projects for some time now. Since words in a sentence are rarely spoken in isolation (i.e. with pauses in between), there is no trivial way for infants to learn where word boundaries are. This has caused researchers to suspect that infants actually employ statistical strategies as a first step in learning word boundaries, in which statistical regularities play an important role \cite{thiessen2003cues}.

Early work on statistical word segmentation relies on the observation that transitions between syllables or phonemes are generally less predictable at word boundaries than within words (\cite{harris1970phoneme}, \cite{saffran1996statistical}), which can give the learner a cue as to whether or not there should be word boundary. Behavioural research has shown that infants are sensitive to this effect \cite{saffran1996statistical} \cite{aslin1998computation}. This gives rise to the assumption that words are units that, to some degree, help predict other units in a sentence.

\cite{Goldwater200921} proposed a Bayesian framework for the statistical word segmentation problem with the goal to identify the assumptions the learner must make in order to correctly segment (real) natural language. They investigate what kind of words learners with different assumptions are able to identify, using a corpus of phonetically transcribed child-directed speech. Specifically, they test the hypothesis that words are statistically independent units, to which end they developed two different models.

The first model is a unigram model: it treats each word independently (i.e. words do not predict later words). They find that this model has a tendency to undersegment the corpus, by identifying frequently co-occuring sequences as a single word. For example, because sequences like \textit{would you} and \textit{that's a} are relatively common, the learner may be tempted to classify these sequences as single words (i.e. \textit{wouldyou} and \textit{thatsa}).

The second model is a bigram model that assumes that words can predict later words. That is, this model assumes that the choice of a word is conditioned on the previous word. Because of this assumption this model is able to greatly reduce the problem of undersegmentation.

Both models in \cite{Goldwater200921} use a (hierarchical) Dirichlet Process (DP) to define probabilities over clustering of word tokens. The Dirichlet process integrates over the number of clusters $K$, and therefore is useful when $K$ is unknown. The probability of assigning a new datapoint $z_i$ to an existing cluster $k$, is proportional to the size of that cluster. The exact probabilities are given by:
\begin{align}
P(z_i=k|\zmin) = 
\begin{cases}
    \frac{n_k^{(\zmin)}}{i - 1 - \alpha},& 1 \le k \le K(\zmin)\\
    \frac{\alpha}{i - 1 - \alpha}              & k = K(\zmin)\\
\end{cases} \label{eq:DP}
\end{align}
where $\zmin$ are the clusters without datapoint $i$, and $n_K^{(\zmin)}$ is the number datapoints assigned to the cluster $k$.

Even though the DP has been found very useful in clustering, the distributions that it prefers do not match the powerlaw distributions that are usually observed over types and tokens. In order to make the DP more suitable for these word distributions, the Pitmann-Yor process (PYP) \cite{pitman1997two} introduces a discount factor $\beta$. The probabilities for clustering become:
\begin{align}
P(z_i=k|\zmin) = 
\begin{cases}
    \frac{n_k^{(\zmin)} - \beta}{i - 1 - \alpha},& 1 \le k \le K(\zmin)\\
    \frac{\alpha + \beta K}{i - 1 - \alpha}              & k = K(\zmin)\\
\end{cases}  \label{eq:PYP}
\end{align}
Indeed, the distributions generated by the PYP model are very close to the empirical distributions of types and tokens \cite{goldwater2005interpolating}.

\todo[inline]{nog meer over model omschrijven?}

The goal of this project is to reproduce the unigram model by \cite{Goldwater200921} and to replicate their results. We experiment with different intialization strategies and parameter values and show their effect on precision, recall and the $F_0$-measure. In a qualitative analysis we show that the unigram model does indeed have a tendency to undersegment the corpus. Finally, we discuss the merits and shortcomings of this model. 

We also implement a unigram model based on the PYP process. We compare this model to the DP unigram model, and investigate the effect of different parameters using a grid search. The DP model structurally outperforms the PYP model. We discuss why this happens, and suggest improvements for this model.
